---
title: RSS:2023 Track 2 (Day 2)
layout: page
---

## Reducing the Attack Surface{#track2-s5}
**David Frier<br>
*October 26, 2023 10:00 am - 10:50 am***

Organizations face an ever-increasing number of threats targeting their valuable data and systems. Understanding the attack surface is crucial for effective information security management. This talk will be an in-depth exploration of the concept of an organization's attack surface and provides practical strategies to understand, track, reduce, and fortify it against cyber threats. By implementing these strategies, organizations can improve their defenses, safeguard critical assets, and mitigate the risks associated with their digital footprint.

## Five Questions to Ask Your Pentest Partner{#track2-s6}
**Qasim Ijaz<br>
*October 26, 2023 11:00 am - 11:50 am***

I've been on the consulting and receiving end of penetration testing services. I've seen how the sauce is made and have been a consumer of this elusive sauce. Over the past decade, I've seen both good and bad penetration tests, and I'm here to tell you it doesn't have to be like this. We, as an industry, can do better. You, as clients, can hold us accountable. This talk consists of five questions that can be asked to start a better evaluation of your penetration testing partners. This is not a complete recipe. Instead, this will serve as a starting point for a larger conversation before the contract is signed.

## Rise of the Machines: The Future of AI in Cybersecurity{#track2-s7}
**Reg Harnish<br>
*October 26, 2023 1:00 pm - 1:50 pm***

"They’re here. Ready or not, machines capable of thinking and making contextual decisions are rapidly gaining momentum – and acceptance – in a world that may not be ready for them. With nearly limitless access to data and processing power, these advanced software engines are now solving important problems in nearly every industry. Like the Terminator 1000 and all its earlier iterations, the machines are fast, capable, and less expensive to operate than their human counterparts. And like the T1000, they are potentially more destructive.
In a world where the incalculable expanse of computer crimes costs billions – these machines may be the only thing that can save us. But who will save us from the machines?"

## FLAME: Federated Learning against Malicious Engineering. Employing Trust and Reputation to Enhance Learning Security and Privacy{#track2-s8}    
**Sergei Chuprov and Leon Reznik<br>
*October 26, 2023 2:30 pm - 3:20 pm***

Federated Learning (FL) is a distributed Machine Learning (ML) technique proposed to enhance the security, privacy, and efficiency of industrial systems. However, attacks against the conventional FL, resulting in compromising local units, have been already reported in practice. We present our novel Reputation and Trust-based mechanisms that allow detecting these compromised local units with the Data Quality analysis and retrospective trust evaluation to improve FL industrial applications. We patented our novel method. We demonstrate our approach on industrial SWIFT financial data and evaluate its effectiveness in improving FL performance and security by detecting data manipulation attacks and excluding compromised units.

## Unlocking Generative AI: Balancing Innovation with Security{#track2-s9}
**Jason Ross<br>
*October 25, 2023 1:00 pm - 1:50 pm***
 
"Unlocking Generative AI: Balancing Innovation with Security" will guide you through the complex terrain of generative AI in corporate settings. Starting with a brief introduction of generative AI, the talk highlights its corporate uses and potential security pitfalls. Explore diverse security threats including data poisoning, supply chain issues, model theft & inversion, and adversarial attacks. Delve into their implications, especially those relevant to large enterprises, such as protection of sensitive data and unauthorized access to AI models. The talk also offers robust mitigation strategies centered on data, model, training, and operational security. Join us as we navigate the promising yet challenging world of generative AI security.
